\section{Motivations and Overview}

Software systems are becoming even more pervasive nowadays.
From simple applications for controlling home appliances to complex tools for dealing with industrial processes, software systems are now found in any environment.
End-user's expectations have also grown along the development of the software industry.
For instance, installing several applications provided by non-fully trusted sources in a mobile phone or closing a window in your office through a website are considered nowadays routinary  tasks which only require engineering effort.
However, the software/hardware industry faces several problems while coping with these expectations.
Among these challenges we find the need to handle millions of users, the ubiquity of resource-constrained devices, and the
open nature of execution environments.   

The widespread usage of interconnected devices and the trend to use client/server architectures have led to a \textit{massive increment in the number of users} some applications have to deal with.
To support so many users, it is necessary to manage a massive computing infrastructure which is both complex and extremely costly.
The emergence of cloud services was a \textit{natural} development of these infrastructures.
Cloud services, which often are used to  build client/server applications,  are all about providing access to computing resources.
They are shipped in many forms (e.g., virtual machines, software) but in general we can reduce them, using a rather simplistic model, to basic resources such as CPU cycles, memory, network bandwidth and storage capacity.
This simplistic view is useful if we consider how important is for cloud services providers to reduce the usage of resources in order to increase efficiency.
For instance, given the large nature of the cloud, a provider of platform as a service (PaaS) can reduce the operational costs if it manages to squeeze even a few thousand of bytes from each request.
As a consequence, carefully managing resources such as CPU and memory becomes a primary concern for cloud service providers.

Despite of the continuous hardware evolution, the demand of applications often surpasses hardware capabilities.
This limitation of resources is particularly clear in wearable devices, but in the near future we can expect to see the same kind of concern in the emergent \textit{Internet of Things}.
In this kind of devices it is fundamental to offer tools for properly sharing the scarce resources among applications.
It is worth noting that managing resources has been a central problem in computer science and software engineer for a long time.
However, I highlight the problem in this context for two reasons.
First, because I think that new technologies to build applications for these devices allow better resource management techniques.
Second, because it shows that limitations in resource quantity is still a concern for software developers.

Open execution environments refer to the possibility of allowing the deployment of applications provided by different sources at any time, being these sources trustworthy or not.
Since end-users are able to install many applications that share the execution environment, it is impossible for the developers of the runtime or of a single application to predict under what condition an application will be executing.
Providing isolation among applications to guarantee a \textit{safe} behavior is then of utmost importance because now it is possible to use these execution environments to build and massively deploy actuators that operate on the physical environment.
A possible source of failure in these applications is the lack of resource isolation.
In short, an application makes another to fail by consuming the resources needed for the later.

The common concern in the three previous problems is that of making applications and execution environments aware and capable of coping with resource limitations.
This concern becomes even more relevant when, instead of looking at these problems in isolation, we observe them as problems that emerge together.
For instance, resource-constrained devices providing an open executing environment are mainstream in wearable devices. 
When an application includes features to react and modify its behavior after resource-related events occurs, it is said to be a resource-aware application.
For a software system to handle this kind of features, it requires the appropriate runtime support.   
This thesis addresses the problem of supporting resource-aware programming in execution environments.
In particular, it aims at offering \textit{``better''} support for collecting data about resource consumption, as well as \textit{``better''} mechanisms to reserve resources for specific applications.

Runtime support for resource-aware programming highly depends on the target technology.
After all, monitoring the memory consumption of \textit{C/C++} applications is different from capturing the memory consumption of a \textit{Lisp} program.
This thesis focuses on facing the issue of resource-awareness in managed runtime environments (MREs) such as the Java Virtual Machine (JVM) and the Common Language Runtime (CLR).
Among the existent solutions to perform resource consumption monitoring and resource reservation in MREs, there are two fundamental drawbacks.
Tackling these drawbacks, which are described below, is the goal of the present work.

\begin{itemize}
\item Existent solutions impose \textbf{significant performance overhead} on the execution of applications.
While this limitation does not affect the utilization of such solutions to, for instance, profile an application during the development phase, it does make impractical using such techniques in a production environment due to the slowdown in execution time or the extra resources required.
As a result, solutions with \textit{high} performance overhead or few provided features are used in those applications where being aware of resources at runtime is an strict requirement.

\item Despite of the widespread utilization of MREs to execute applications based on components and other abstractions, \textbf{creating resource management tools} for these abstractions is still \textbf{a complex task}.
Indeed, creating abstractions such as domain-specific languages (DSLs) and components models is increasingly common.
Plenty of tooling support exists for doing so, specially to define new DSLs.
In addition, quite often these abstractions target MREs as backend technologies due to their safety.
However, new abstractions poses a challenge for developers when it comes to profiling, debugging and monitoring applications that are built using them.
The challenge emerges because the new abstractions are not always shipped along custom profilers and debuggers.
As a consequence, developers find themselves using mainstream tools which are only able to cope with \textit{``classical''} concepts such as \textit{objects}, \textit{methods} and \textit{memory locations}, instead of more specific concepts.
The reason for this is that defining tooling support for a specific abstraction is a time consuming task that must be balanced against the limited audience of such an abstraction.
\end{itemize}
 
\section{Contributions}

\begin{enumerate}
\item A methodology for resource-management-aware component deployment.
\item An optimistic resource monitoring approach that reduces the performance overhead.
\item A domain-specific language to developed custom memory profilers.
\end{enumerate}
