%-----------------------------%
\selectlanguage{english}
\chapter{Scapegoat: Spotting the Faulty Component in Reconfigurable Software Systems}
\label{chp:scapegoat}
\markboth{Scapegoat: Spotting the Faulty Component in Reconfigurable Software Systems}{Chapter5}
%-----------------------------%

\coolphrase {
	\textbf{(\emph{Snot's} dead body lay down on the ground)} \\
	\vspace{1 mm}
	
	\emph{Witness} - And like every time, \emph{Snot}, he would fade a few shooters,\\
				     you know. Play it out until the pot's deep. Then he\hspace*{7 mm} \\
				     would snatch and run, you see what I'm saying?\hspace*{12 mm} 
	\vspace{1 mm}
	
	\emph{McNulty} - Every time?\hspace*{73 mm} 
	\vspace{1 mm}
	
	\emph{Witness} - Couldn't help himself.\hspace*{57 mm} 
	\vspace{1 mm}
	
	\emph{McNulty} - [\dots] You let him do this?\hspace*{50 mm} 
	\vspace{1 mm}
	
	\emph{Witness} - Naw man. We catch him and kick his [\dots]\hspace*{22 mm} 
	\vspace{1 mm}
	
	\emph{McNulty} - I got to ask you [\dots] -- if he did that every time -- why\hspace*{3 mm} \\
				   did you even let him into the games?\hspace*{32 mm} 
	\vspace{1 mm}
	
	\emph{Witness} - Huh?\hspace*{85 mm} 
	\vspace{1 mm}
	
	\emph{McNulty} - If \emph{Snot} always stole the money, why did you let him\hspace*{7 mm} \\
					 play?\hspace*{84 mm} 
	\vspace{1 mm}
	
	\textbf{(\emph{Witness} looks at \emph{McNulty} like he's an idiot)}
	\vspace{1 mm}
	
	\emph{Witness} - Got to \textbf{(pause)} this America, man.\hspace*{36 mm} 
}{The Wire, Season 1, Episode 1}


%Modern component frameworks support continuous deployment and simultaneous execution of multiple software components on
%top of the same virtual machine.
%However, isolation between the various components is limited.
%A faulty version of any one of the software components can compromise the whole system by consuming all available resources.
%In this paper, we address the problem of efficiently identifying faulty software components running simultaneously in a single virtual machine.
%Current solutions that perform permanent and extensive monitoring to detect anomalies induce high overhead on the system,
%and can, by themselves, make the system unstable.
%In this paper we present an optimistic adaptive monitoring system to determine the faulty components of an application.
%Suspected components are finely analyzed by the monitoring system, but only when required.
%Unsuspected components are left untouched and execute normally.
%Thus, we perform localized \textit{just-in-time} monitoring that decreases the accumulated overhead of the monitoring system.
%We evaluate our approach on two case studies against a state-of-the-art monitoring system and show that our technique correctly
%detects faulty components, while reducing overhead by an average of 92.98\%.


%\section{Introduction}\label{sec:intro}

%Modern computing systems, such as home automation, pervasive and ubiquitous systems are becoming a larger part of our lives.
%The tight connection with our living environment introduces new needs for these systems, such as the co-evolution of the system with its environment, the adaptation of the system to available resources and to users' behaviours, and the reliability of the system in front of faulty or malicious behaviours.
%Modern component frameworks assist software developers in coping with these new needs by providing introspection, reconfiguration, advanced technical services, among other facilities.
%These frameworks provide extensible middleware and assist developpers in managing technical issues such as security, transaction management, or distributed computing.
%They also support the simultaneous execution of multiple software components on the same virtual machine \cite{OSGI:r5,Kevoree,bruneton06}.
%% layer based ?
%
%While component frameworks simplify the programming model for software developers, the isolation between the various components is limited because they are collocated on the same virtual machine.
%This allows components to communicate efficiently and to share references to complex objects, something which is generally not possible when crossing the process boundary.
%However, one faulty software artifact may compromise the whole system by, for example, consuming all available resources on the machine.
%Furthermore, because these systems evolve in open environments where humans have central roles, software developers are unable to anticipate all future configurations of the application  at design-time \cite{baresi2006toward}.
%In these highly unpredictable environments, detecting irregular behaviour and maintaining the system in a consistent state is an important concern that can be addressed through continuous monitoring.

State of the art monitoring systems \cite{FrenotS04,KregerHaroldWilliamson03,Binder200645} collect data about the internal state of applications at runtime, such as the time spent executing a component, the amount of I/O and memory used, and the number of calls to a component.
The overhead that these monitoring systems introduce into applications is high, which makes it unlikely for them to be used in production systems.
Results presented in \cite{Binder:2009:PPV:1464245.1464249} show that overhead due to fine-grain monitoring systems can be up to a factor of 4.3.
The experiments presented in this chapter show that overhead grows with the size of the monitored software.
Thus, overhead greatly limits the scalability and usage of monitoring systems.

In this chapter, we address excessive overhead in monitoring approaches by introducing an optimistic adaptive monitoring system - Scapegoat - that provides lightweight global monitoring under normal conditions, and precise and localized monitoring when problems are detected.
Although our approach reduces the accumulated amount of overhead in the system, it also introduces a delay in finding the source of a faulty behaviour.
Our objective is to provide an acceptable trade-off between the overhead and the delay to identify the source of faulty behaviour in the system.

Our optimistic adaptive monitoring system is based on the following principles:
\begin{itemize}
\leftskip -.2in % see comments below
%\parindent -4in % see comments below
 \item \textbf{Contract-based resource usage.}
The monitoring system follows component-based software engineering principles. 
Each component is augmented with a contract that specifies their expected or previously calculated resource usage~\cite{Beugnard774917}. 
The contracts specify how a component uses memory, I/O and CPU resources.
 \item \textbf{Localized just-in-time injection and activation of monitoring probes.} 
Under normal conditions our monitoring system performs a lightweight global monitoring of the system. 
When a problem is detected at the global level, our system activates local monitoring probes on specific components in order to identify the source of the faulty behaviour.
The probes are specifically synthesized according to the component's contract to limit their overhead.
Thus, only the required data are monitored (e.g., only memory usage is monitored when a memory problem is detected), and only when needed.
  \item \textbf{Heuristic-guided search of the problem source.} 
We use a heuristic to reduce the delay of locating a faulty component while maintaining an acceptable overhead.
This heuristic is used to inject and activate monitoring probes on the suspected components. 
However, overhead and latency in finding the faulty component are greatly impacted by the precision of the heuristic.
A heuristic that quickly locates faulty components will reduce both delays and the accumulated overhead of the monitoring system.
We propose using Models@run.time techniques in order to build an efficient heuristic.
\end{itemize}

The evaluation of our optimistic adaptive monitoring system shows that, in comparison to other state-of-the-art approaches, the overhead of the monitoring system is reduced by up to 92.98\%.
Regarding latency, our heuristic reduces the delay to identify the faulty component when changing from global, lightweight monitoring to localized, just-in-time monitoring.
We also present a use case to highlight the possibility of using Scapegoat on a real application, that shows how to automatically find buggy components on a scalable modular web application.

The remainder of this chapter is organized as follows.
Section~\ref{sec:scapegoat-motivaing-example} motivates our work through a case study which is used to validate the approach.
A brief description of Kevoree, a platform for distributed component-based software development, is presented in Section~\ref{sec:kevoree-intro}.
Section~\ref{sec:scapegoat-approach} provides an overview of the Scapegoat framework.
It highlights how the component contracts are specified, how monitoring probes are injected and activated on-demand, how the Scapegoat framework enables the definition of heuristics to detect faulty components without activating all the probes, and how we benefit from Models@run.time to build efficient heuristics.
Section~\ref{sec:evaluation} evaluates the approach through a comparison of detection precision and detection speed with other approaches.
Section~\ref{sec:WebStudy} presents a use case based on an online web application\footnote{\url{http://cloud.diversify-project.eu/}} that leverages software diversity for safety and security purposes.
Finally, Section~\ref{sec:conclusion} discusses the approach and presents the conclusions of this chapter.

\input{chapter5/background.tex}
\input{chapter5/approach.tex}
\input{chapter5/eval.tex}
%\input{chapter5/related_work.tex}

\section{Conclusions}\label{sec:conclusion}
In this chapter we presented Scapegoat, an adaptive monitoring framework to perform lightweight yet efficient monitoring of Component-Based Systems.
In Scapegoat, each component is augmented with a contract that specifies its resource usage, such as peak CPU and memory consumption.
Scapegoat uses a global monitoring mode that has low overhead on the system, and an on-demand fine-grained localized monitoring mode that performs extensive checking of the components' contracts.
The system switches from the global monitoring mode to the localized monitoring mode whenever a problem is detected at the global level in order to identify the faulty component.
Furthermore, we proposed a heuristic that leverages information produced by the Models@run.time approach to quickly predict the faulty components. 

Scapegoat has been implemented on top of the Kevoree component framework which uses the Models@run.time approach to tame the complexity of distributed dynamic adaptations.
The evaluation of Scapegoat shows that the monitoring system's overhead is reduced by up to 92.98\% in comparison with state-of-the-art full monitoring systems. 
The evaluation also presents the benefits of using a heuristic to predict the faulty component.
In the second part of the evaluation, we highlighted the benefit of Scapegoat on a classical web server architecture to dynamically determine faulty components.
This second example also exposes the capacity of Scapegoat to be applied to different application domains and confirms its relatively low overhead on the running system.
Scapegoat contributes to the state of the art by providing a monitoring framework which adapts its overhead depending on current execution conditions and leverages the architectural information provided by Models@run.time to drive the search for the faulty component.

The approach proposed in this chapter contributes to answer two research questions that were presented in the introduction of this thesis (see Section \ref{sec:intro-challenges}).
In particular, it answers \textit{\ref{rq:rq1}} (\textit{How can we provide portable and efficient support for resource consumption monitoring?}) by describing a monitoring framework that produces low performance overhead and is fully portable.
Likewise, our proposal partially answers \textit{\ref{rq:rq3}} (\textit{How can we leverage the knowledge about the architecture of applications to drive
a mechanism for resource management?}) by using knowledge about the structure of applications to drive the behavior of the framework.

